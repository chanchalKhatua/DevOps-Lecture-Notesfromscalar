# **Docker Container Networking and Security (Continued)**

This document covers **Docker Networking types**, a **demo on creating a bridge network**, **common interview questions**, and **Docker security best practices**.

---

## **Topics to be discussed:**
1. Docker Networking  
2. Demo: Creating a Network  
3. Interview Questions  
4. Security - Best Practices  

---

# **Docker Networking**

Docker Networking is essential for enabling communication between containers, the host system, and external networks. Docker provides multiple networking modes for different use cases.
---

## 🚢 Docker Networking Overview

- Docker networks are **isolated environments** that allow containers to communicate securely.
- By default, Docker provides several built-in networks: `bridge`, `host`, `none`.
- You can create custom user-defined networks for better control and scalability.

---

## 🧠 Key Concepts

| Concept                          | Description |
|----------------------------------|-------------|
| **Docker Host**                 | The machine running Docker (e.g., EC2 instance) |
| **Container Internal (CI) Host** | The hostname or internal network of the container |
| **CI External Network**         | External access network for CI (e.g., the internet) |
| **Isolated Networks**           | Networks created to isolate container traffic |

---

## 🛠️ Docker Networking Commands

### 🔍 Listing Docker Networks
```bash
docker network ls
```

### 🔎 Inspecting a Network
```bash
docker network inspect <network-name>
```

### ➕ Creating a New Network
```bash
docker network create <network-name>
```

### 🔗 Connecting a Container to a Network
```bash
docker network connect <network-name> <container-name>
```

### ❌ Disconnecting a Container from a Network
```bash
docker network disconnect <network-name> <container-name>
```

### 🧹 Removing a Network
```bash
docker network rm <network-name>
```

> ⚠️ Note: A network cannot be removed if any container is connected to it.

### 🚀 Run a Container with a Specific Network
```bash
docker run --network <network-name> <image>
```

### 🧽 Prune Unused Networks
```bash
docker network prune
```
> ⚠️ Be careful: This removes all **unused** networks.

---
### **Types of Docker Networks**

| **Network Type** | **Description**                                    |
|------------------|----------------------------------------------------|
| **Bridge**       | Default network. Containers can communicate within the same host. |
| **Host**         | Removes network isolation between the container and the host. |
| **None**         | Disables networking for a container.               |
| **Overlay**      | Enables communication between containers on different hosts. |
| **Macvlan**      | Gives each container a unique MAC address, making them appear as physical devices on the network. |

---

## **1. Bridge Network**  
A **Bridge Network** is the **default network** created by Docker. Containers on the same bridge network can communicate with each other using **names** or **IP addresses**.
  - Containers on default bridge network can't communicate with host name but can communicate using IP address  
  - Default bridge network doesn't include a dns to resolve container names
---
# **Demo: Creating a Bridge Network**
## 🧪 Create Two Containers

```bash
docker run -dit --name container1 alpine sh
docker run -dit --name container2 alpine sh
```

---

## 🔍 Check IP Addresses of Containers

```bash
docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container1
docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container2
```

This will show the internal IPs assigned by Docker to each container.

---

## 🌐 Bridge Network Behavior

- Containers on the **default bridge network**:
  - ✅ Can communicate with **each other using IP addresses**
  - ❌ Cannot resolve **hostnames** of other containers
  - ❌ Cannot communicate using container names (no internal DNS)

---

## 🔧 Test Container Communication

### Access `container1`
```bash
docker exec -it container1 sh
```

### Inside `container1`, try:
```sh
ping <container2-IP>     # ✅ Should succeed
ping container2          # ❌ Will fail (no DNS resolution in default bridge)
```

**user-defined bridge networks, container communication, and disabling ICC (Inter-Container Communication)** in Docker:

---

## 🧱 Create a User-Defined Bridge Network

```bash
docker network create my_bridge
```

- This network allows **automatic DNS resolution**, so containers can communicate using names.

---

## 🚀 Run Containers in the User-Defined Bridge

```bash
docker run -dit --name container1 --network my_bridge alpine sh
docker run -dit --name container2 --network my_bridge alpine sh
```

---

## 🔍 Inspect Network to See Containers

```bash
docker network inspect my_bridge
```

- You’ll see `container1` and `container2` listed under the `Containers` section.

---

## ✅ Test DNS Resolution (Inside `container1`)

```bash
docker exec -it container1 sh
ping container2   # ✅ Should work using container name
```

---

## ❌ What Happens with Default Bridge?

```bash
docker run -dit --name container3 alpine sh
```

- This runs on the **default bridge network**.
- Default bridge **does not support DNS resolution** → communication via container name **fails**.
- Also, **ICC (Inter-Container Communication)** can be disabled to restrict even IP-based communication.

---

## 🔒 Disabling ICC (Inter-Container Communication)

ICC = Inter-Container Communication (controls whether containers on the same bridge can talk to each other)

To disable ICC on the **default bridge**:
com.docker.network.bridge.enable_icc need to be false
### 1. Edit Docker daemon config:

```bash
sudo nano /etc/docker/daemon.json
```

Add:
```json
{
  "bridge": "docker0",
  "icc": false
}
```

### 2. Restart Docker:

```bash
sudo systemctl restart docker
```

---

## 🔥 Blocking ICC with iptables (Alternative) Host level

```bash
sudo iptables -I DOCKER-USER -i docker0 -o docker0 -j DROP
```

> This inserts a rule that **drops all traffic between containers** on the `docker0` bridge interface.

---
![image](https://github.com/user-attachments/assets/4718990d-f048-4879-af56-41d6c736a087)

 

---

## **2. Host Network**  
In a **Host Network**, the container shares the **host’s network stack**, removing network isolation.  
- **No Port Isolation**: Containers share the same ports as the host.  
- **Security Issue**: Port conflicts can occur.
-  And use host's IP Addressed.
---

## 🔌 Docker Host Networking with NGINX

### 🧠 Key Concepts:
- **Host Networking:** The container shares the host's network stack (i.e., no port mapping needed).
- **Use Case:** Useful when low latency or direct port access is required.

---

### 🧪 Basic Example

#### Run an NGINX container using host networking:

```bash
docker run -d --network host --name host_net_demo -it nginx
```

> ✅ This binds NGINX directly to the host's ports (default: 80). No `-p` needed.

#### Test with curl:

```bash
curl http://localhost
```

---

## ⚠️ Limitation: Port Conflict

- When using host networking, containers **cannot share the same port**.
- Example:
  ```bash
  docker run --rm --network host --name nginx1 -d nginx
  docker run --rm --network host --name nginx2 -d nginx  # ❌ Will fail because port 80 is already in use
  ```

---

## ⚙️ Custom NGINX Configuration on Different Port (e.g., 8080)

### Example: `nginx.conf`

```nginx
worker_processes 1;
events {
    worker_connections 1024;
}
http {
    server {
        listen 8080;
        server_name localhost;
        location / {
            root /usr/share/nginx/html;
            index index.html index.htm;
        }
    }
}
```

### Run NGINX container with custom config:

```bash
docker run --network host \
  -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf:ro \
  -d nginx
```

#### Test:

```bash
curl http://localhost:8080
```

✅ You can now access your custom NGINX server on port 8080.

---

## 📁 Bind Mount (Serving Custom Content)

- Use bind mount to serve files from the local system inside the container:

```bash
docker run --network host \
  -v $(pwd)/html:/usr/share/nginx/html \
  -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf:ro \
  -d nginx
```

> Now your custom HTML and config are served by NGINX.

---
---

## **3. None Network**  
A **None Network** completely disables networking for a container.  
- Useful for **containers that do not require external communication**.
![image](https://github.com/user-attachments/assets/d7af1d0b-8522-465d-924e-03005596578c)

### **Command to Use None Network**:  
```bash
docker run -d --name app --network none
```
❓ Q1: What happened when you tried Hostname -I?
❌ A2:
It failed because you typed Hostname with an uppercase H, which is not recognized. Linux commands are case-sensitive.

You fixed it by using the correct lowercase version: hostname -I.

❓ Q2: What does this output mean?
bash
Copy
Edit
hostname -I
172.23.232.133 172.18.0.1 172.17.0.1 172.19.0.1
✅ A3:
These are the IP addresses assigned to the container across different Docker networks:

172.23.232.133 – likely from a custom or overlay network

172.17.0.1, 172.18.0.1, 172.19.0.1 – bridge network interfaces or other custom networks

❓ Q3: Why are there multiple IP addresses?
✅ A4:
Because the container is connected to multiple Docker networks. Each network assigns a different IP address to the container.

---

## **4. Overlay Network**  
An **Overlay Network** enables communication between containers across **multiple Docker hosts**.  
- Primarily used in **Docker Swarm**.  
- It creates a **virtual network** that spans across nodes.
![image](https://github.com/user-attachments/assets/42cea2ad-186e-4305-bb3c-15cf7a838d70)

-❓ Q1: Can the Worker Nodes communicate with each other directly (e.g., Worker 1 ↔ Worker 2)?
❌ A3: No, Worker 1 cannot ping Worker 2 over the overlay network.

-❓ Q2: What might be causing this issue?
🛠️ A4: Possible reasons include:

-Security Group (AWS EC2) Restrictions – Required ports may not be open between Worker nodes.

-Firewall Rules – OS-level firewall (like iptables or firewalld) might be blocking traffic.

-Overlay Network Misconfiguration – The Docker overlay network may not be set up correctly or may be experiencing issues.

-Docker Swarm Gossip Network Failure – Underlying gossip communication between nodes may be interrupted.

## **Overlay Network in Docker Swarm and deploying an Nginx service with two replicas using that network. Here's a breakdown:**

### **Command Breakdown**
#### 1️⃣ Create an Overlay Network for Swarm
```sh
docker network create --driver overlay --scope swarm my_custom_overlay
```
- `--driver overlay`: Uses the **overlay** network driver, which enables multi-host communication in Swarm.
- `--scope swarm`: Ensures the network is **Swarm-scoped** (used only in Swarm mode).
- `my_custom_overlay`: The custom network name.

#### 2️⃣ Deploy an Nginx Service with Two Replicas
```sh
docker service create --name nginx_web --replicas 2 --network my_custom_overlay nginx:latest
```
- `--name nginx_web`: Service name.
- `--replicas 2`: Deploys **two instances** of the Nginx container.
- `--network my_custom_overlay`: Connects the service to the custom overlay network.
- `nginx:latest`: Uses the latest Nginx image.

### **Verification & Debugging**
✅ **List Docker Networks**  
```sh
docker network ls
```
Check if `my_custom_overlay` is listed.
---

## **5. Macvlan Network**  
A **Macvlan Network** assigns each container a **unique MAC address**, making the containers appear as **separate physical devices** on the network.

### **Command to Create a Macvlan Network**:  
```bash
docker network create -d macvlan --subnet=192.168.1.0/24 --gateway=192.168.1.1 -o parent=eth0 network_name
```
---
## **5.  IPvlan Network** 
---
**IPvlan in L2 mode** is an excellent solution for cloud-native applications that require containers to have IP addresses routable from external networks. Here’s a deeper look at why this approach works well:

### **Why Use IPvlan L2 for Cloud-Native Applications?**
1. **Routable IPs:**  
   - Containers get IPs in the same subnet as the host, making them accessible without NAT (unlike bridge networks).
   
2. **Simplified Networking:**  
   - No need for port mappings or overlays; each container can communicate with external services directly.

3. **Better Performance:**  
   - Unlike macvlan, which creates a new MAC per container, **IPvlan L2** reduces overhead by keeping a single MAC address for all containers, improving performance in environments where MAC filtering is strict.

4. **Improved Compatibility with Cloud Services:**  
   - Some cloud environments don’t support multiple MAC addresses per instance (which macvlan requires), but **IPvlan L2 works with a single MAC**, making it more cloud-friendly.

---

### **Steps to Implement IPvlan L2**
#### **1. Create an IPvlan L2 Network**
```bash
docker network create -d ipvlan \
 --subnet=192.168.1.0/24 \
 --gateway=192.168.1.1 \
 --ipvlan-mode=l2 \
 -o parent=eth0 ipvlan_l2_network
```
- `-d ipvlan`: Specifies IPvlan as the driver.  
- `--ipvlan-mode=l2`: Uses Layer 2 mode, meaning containers share the same MAC address as the parent interface.  
- `-o parent=eth0`: Assigns the parent network interface.

#### **2. Run a Container on the IPvlan Network**
```bash
docker run -it --rm --network=ipvlan_l2_network \
  --ip=192.168.1.100 alpine sh
```
- The container gets the IP `192.168.1.100`, which is **directly accessible from the LAN**.

---

### **When to Use IPvlan L2 Over Other Networking Modes?**
| **Networking Mode** | **Best Use Case** |
|----------------------|------------------|
| **Bridge** | Default for local container networking (requires NAT) |
| **Host** | When you want the container to share the host’s network stack |
| **Macvlan** | When each container needs its own unique MAC address (not always cloud-friendly) |
| **IPvlan L2** | Best for cloud-native apps where containers need IPs from the host’s subnet |


# **Interview Questions**

### **Q1: How Will You Expose Your Containers Externally?**

**Answer:** There are multiple ways to expose Docker containers:  
1. **Port Binding**:  
   Use the `-p` option to bind the container port to a host port.  
   ```bash
   docker run -d -p 8080:80 nginx
   ```

2. **Docker Compose**:  
   Define port binding in the `docker-compose.yml` file.  
   ```yaml
   ports:
     - "8080:80"
   ```

3. **Swarm Services**:  
   Use the `--publish` option to expose services.  
   ```bash
   docker service create --name my_service --publish published=8080,target=80 nginx
   ```

4. **Proxy Servers**:  
   Use **NGINX** or **HAProxy** as a **reverse proxy** to handle requests to the container.

---

### **Q2: What Are Common Issues with Docker Containers and How Do You Troubleshoot Them?**

| **Issue**                   | **Troubleshooting Steps**                       |
|-----------------------------|-------------------------------------------------|
| **Connectivity Issues**      | Check container network settings.              |
| **DNS Resolution**           | Check if the container can resolve DNS names.  |
| **Port Binding Conflicts**   | Use `netstat -tupln` to check for conflicts.   |
| **Performance Degradation**  | Monitor resource usage and network traffic.    |

### **Troubleshooting Commands**
1. **Inspect Container Networks**:  
   ```bash
   docker network inspect <network_name>
   ```

2. **Check Connectivity Using Ping**:  
   ```bash
   docker exec -it <container_id> ping <target>
   ```

3. **Check DNS Settings**:  
   - By default, Docker uses the **host DNS settings**.  
   - To change the DNS:  
     ```bash
     docker run -d --name my_container --dns 8.8.8.8 nginx
     ```

4. **Check Ports in Use**:  
   ```bash
   netstat -tupln
   ```

5. **Check Container Logs**:  
   ```bash
   docker logs <container_id>
   ```

6. **Monitor Network Traffic Using tcpdump**:  
   ```bash
   tcpdump -i eth0
   ```

---

# **Security - Best Practices**

### **1. Signing Images**  
- Use **signed images** to ensure the authenticity of Docker images.  
- **Command to Check Image Signature**:  
  ```bash
  docker trust inspect --pretty nginx
  ```

---

### **2. MTLS (Mutual TLS Authentication)**  
**MTLS** ensures that both the client and server authenticate each other using **certificates**.

#### **Steps to Enable MTLS:**
1. **Generate Certificates**  
   - Create **CA**, **server**, and **client certificates**.

2. **Configure Docker Daemon**  
   - Modify the **`daemon.json`** file:  
     ```json
     {
         "tls": true,
         "tlscacert": "/path/to/ca.pem",
         "tlscert": "/path/to/server-cert.pem",
         "tlskey": "/path/to/server-key.pem",
         "tlsverify": true
     }
     ```

3. **Restart Docker Daemon**  
   ```bash
   systemctl restart docker
   ```

---

### **3. Generating a Certificate (Practical Example)**

#### **Steps to Generate Certificates:**
1. **Generate CA Key & Certificate**  
2. **Generate Server Key & Certificate**  
3. **Sign the Server Certificate**  
4. **Generate Client Key & Certificate**  
5. **Sign the Client Certificate**

# **Summary of Key Commands**

| **Command**                        | **Description**                                    |
|------------------------------------|----------------------------------------------------|
| `docker network create`             | Creates a new Docker network.                     |
| `docker network ls`                 | Lists all Docker networks.                        |
| `docker network inspect`            | Inspects a specific network.                      |
| `docker run --network <network>`    | Runs a container in a specific network.           |
| `netstat -tupln`                    | Lists all active ports and services.              |
| `docker trust inspect --pretty`     | Checks the signing authority of a Docker image.   |

---

# **Conclusion**

This session covered **Docker Networking**, a **demo on creating networks**, common **interview questions**, and **security best practices**.  
Make sure to practice using **networks and security features** to strengthen your understanding of Docker.
