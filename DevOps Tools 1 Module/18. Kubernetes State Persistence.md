# Kubernetes State Persistence

---





## Network Policies



### **Overview:**
Network policies define rules for how pods communicate with:
- Each other.
- External endpoints.

Policies can manage both **ingress** (incoming traffic) and **egress** (outgoing traffic).

### **Key Concepts:**
1. **Selectors:**
   - Used to identify the pods to which the policy applies.
   - Example: A policy might target pods labeled `app=frontend`.
   - **Example:** Consider a microservices architecture where you only want the `frontend` pod to communicate with the `backend` pod but restrict it from accessing the `database` pod. Using selectors, you can define this scope effectively.

2. **Ingress Rules:**
   - Define the allowed incoming traffic to pods.
   - Example: Allow HTTP traffic on port 80 from a specific pod group.
   - **Example:** If a `shopping-cart` pod accepts traffic from a `user-session` pod, the ingress rule can specify that only requests on port 8080 (HTTP) are allowed while blocking others.

3. **Egress Rules:**
   - Define the allowed outgoing traffic from pods.
   - Example: Allow outgoing requests to a database pod.
   - **Example:** A `logging` pod might need to send data to an external monitoring service. The egress rule can restrict traffic to only the specific IP address of that service.

4. **Policy Types:**
   - **Ingress:** Rules for incoming traffic.
   - **Egress:** Rules for outgoing traffic.
   - Both can be used simultaneously to create comprehensive traffic policies.
   
 ![image](https://hackmd.io/_uploads/HkazMxsrJg.png)

### **Lab Workflow:**
1. **Deploy an Application:**
   - Example: Deploy a web application that communicates with a database pod.
   - **Example:** Deploy a `frontend` service that interacts with both a `backend` service and a `cache` service while limiting communication to specific ports and protocols.

2. **Deploy a Second Pod with Specific Policies:**
   - Create a pod with policies to allow only certain traffic.
   - Example: Deploy a monitoring pod that only listens to logs from the application pod.

3. **Create an Allow Policy:**
   - Example: Permit HTTP traffic from pod `frontend` to pod `backend`.
   - **Example:** Create a policy to allow TCP connections from a `worker` pod to a `queue` pod only on port 5672 for message queueing.

4. **Create a Deny Policy:**
   - Example: Block all other traffic except necessary requests.
   - **Example:** Deny all outbound traffic from a `debug` pod except for SSH connections to a specific admin server.

---

## Volumes in Kubernetes



### **Types of Volumes:**
1. **ConfigMap as Volume:**
   - Mount configuration data as files or environment variables.
   - Example: Store database connection strings in a `ConfigMap` and use it in pods.
   - **Detailed Example:** A `ConfigMap` containing multiple configurations (e.g., environment-specific variables for dev, staging, and production) can be mounted as a volume, ensuring consistent deployment across environments.
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: "mysql://db.example.com:3306"
  max_connections: "100"
  app-config.json: |
    {
      "log_level": "debug",
      "retry_count": 5
    }

---
apiVersion: v1
kind: Pod
metadata:
  name: configmap-demo
spec:
  containers:
    - name: myapp
      image: busybox
      command: ["sleep", "infinity"]
      volumeMounts:
        - name: config-volume
          mountPath: /config
  volumes:
    - name: config-volume
      configMap:
        name: app-config
```

2. **Secret as Volume:**
   - Store sensitive data like passwords or tokens securely.
   - Example: Mount an API token secret as a volume.
   - **Example:** Use a `Secret` to store TLS certificates for a secure connection between pods.

3. **HostPath:**
   - Maps a directory or file on the host nodeâ€™s filesystem to a pod.
   - Example: Use host paths to share logs between the host and pod.
   - **Example:** Map a specific directory, such as `/var/logs/app`, from the host node to a pod for real-time log monitoring.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hostpath-demo
spec:
  containers:
    - name: busybox
      image: busybox
      command: ["/bin/sh", "-c"]
      args:
        - while true; do
            echo "$(date) - Log entry from pod" >> /var/log/app-logs/demo.log;
            sleep 5;
          done
      volumeMounts:
        - mountPath: /var/log/app-logs
          name: host-volume
  volumes:
    - name: host-volume
      hostPath:
        path: /var/log/app-logs  # Host directory to be mounted
        type: DirectoryOrCreate  # Creates the directory if it does not exist

```
4. **EmptyDir:**
    ## Overview
`emptyDir` is a temporary volume type in Kubernetes that is created when a pod starts and exists as long as the pod runs. When the pod is deleted, the data inside the `emptyDir` is lost.

A temporary directory is created when a pod is assigned to a node. The data is cleared when the pod stops.

## Key Features
### Ephemeral Storage
- The `emptyDir` volume is created when a pod starts.
- The data is lost when the pod is deleted.

###  Persistence Across Container Restarts
- If a container inside the pod restarts, the `emptyDir` data remains intact.
- If the pod is deleted, the `emptyDir` is also removed.

###  Shared Storage Between Containers
- Multiple containers within the same pod can use `emptyDir` to share data.

###  Temporary Storage
- Ideal for caching, temporary logs, or intermediate data processing.
- Example: Cache data processing results temporarily.
- Example: Use `emptyDir` for temporary storage in a data analytics pipeline where intermediate results need to be processed within the same pod lifecycle.

###  Performance Optimization
- When configured with `{ medium: "Memory" }`, `emptyDir` stores data in RAM instead of disk, making it **very fast**.
- Example:
  ```yaml
  volumes:
  - name: cache-volume
    emptyDir:
      medium: "Memory"
  ```

## Example Pod Definition Using `emptyDir`
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    app: myapp
spec:
  containers:
  - name: myapp
    image: alpine:latest
    command: ['sh', '-c', 'while true; do echo "logging $(date)" >> /opt/logs.txt; sleep 1; done']
    volumeMounts:
    - name: data
      mountPath: /opt
  - name: logshipper
    image: alpine:latest
    command: ['sh', '-c', 'tail -F /opt/logs.txt']
    volumeMounts:
    - name: data
      mountPath: /opt
  volumes:
  - name: data
    emptyDir: {}
```
![image](https://github.com/user-attachments/assets/3b15d554-3d15-4f18-9bb7-f0139d58aece)

## Use Cases
- Temporary scratch space for processing data
- Caching between containers in a pod
- Storing logs temporarily before processing
- Temporary storage in data analytics pipelines
![image](https://hackmd.io/_uploads/rkyK7gorye.png)

---

## Persistent Volumes (PV), Claims (PVC), and Storage Classes



### **Persistent Volumes (PV):** 
A Persistent Volume (PV) is a storage resource in Kubernetes that provides a way to manage durable storage separately from the lifecycle of Pods. PVs allow stateful applications to persist data across Pod restarts and rescheduling. It is a **pre-provisioned storage resource** in the cluster, managed by an administrator. 
- **1. Independent of Pod Lifecycle:** Persistent storage remains even after pod deletion.
    - Pods can be rescheduled on other nodes.
- **2. Storage Capacity**
      - Storage capacity in Persistent Volumes (PVs) and Persistent Volume Claims (PVCs) defines how much storage a Pod can use. It is 
      specified in the capacity field of a PV and the resources.requests.storage field of a PVC.
- **3. Access Modes:**
   - **ReadWriteOnce:** Mounted by a single node for read/write.
   - **ReadOnlyMany:** Mounted by multiple nodes as read-only.
   - **ReadWriteMany:** Mounted by multiple nodes for read/write.
     
     ![image](https://github.com/user-attachments/assets/76b0ff36-deb6-4b31-9b87-f1ecb695cb78)

- **4. Reclaim Policies:**
  

   A **Reclaim Policy** defines what happens to a **Persistent Volume (PV)** when the associated **Persistent Volume Claim (PVC)** is 
     deleted. Kubernetes supports three reclaim policies:

   | **Reclaim Policy** | **Description** |
   |--------------------|----------------|
   | `Retain` | The PV remains after the PVC is deleted, preserving the data. Manual cleanup is required. |
   | `Delete` | The PV and its associated storage are deleted when the PVC is deleted. (Common in cloud environments like AWS EBS, GCE PD, 
     etc.) |
   | `Recycle` (Deprecated) | The PV is scrubbed (basic file deletion) and made available again. Not recommended for production. |

  ---

   ### **1. Retain Policy (Manual Cleanup Required)**
     - The PV is **not deleted** after the PVC is removed.
     - The data remains on the volume for **manual backup or reassignment**.
     - To reuse the PV, an admin must **manually delete it** or bind it to another PVC.

    ### **Example PV with `Retain` Policy**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: retained-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: "/mnt/data"
```

  ### **What Happens?**
   1. The **PVC is deleted**, but the **PV remains**.
   2. The PV status changes to `Released`, but it is **not automatically reused**.
   3. Admin must **manually delete or recycle** the PV before it can be claimed again.

---

  ## **2. Delete Policy (Automatic Cleanup)**
   - The PV and its associated **storage resource are deleted** when the PVC is deleted.
   - This is commonly used for **dynamically provisioned volumes** in cloud environments.

 ### **Example PV with `Delete` Policy**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: deletable-pv
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: fast-storage
  gcePersistentDisk:
    pdName: my-disk
    fsType: ext4
```

 ### **What Happens?**
   1. The **PVC is deleted**.
   2. The associated **PV and underlying storage are also deleted**.
   3. The **storage cannot be recovered**.


---

## **3. Recycle Policy (Deprecated)**
- The PV is **scrubbed** (basic file deletion) and **made available again**.
- This method is insecure because it does not guarantee complete data erasure.
- Kubernetes **deprecated** this feature in v1.11.
- Instead, **use dynamic provisioning** or **manually reclaim storage**.

### **Example PV with `Recycle` Policy (Not Recommended)**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: recycled-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  hostPath:
    path: "/mnt/recycle"
```

### **What Happens?**
1. When the **PVC is deleted**, Kubernetes performs a **basic cleanup** (deleting files inside the PV).
2. The **PV is made available for reuse** by a new PVC.
3. **Not recommended** for sensitive data or production use.

---

## **Choosing the Right Reclaim Policy**
| **Use Case** | **Recommended Reclaim Policy** |
|-------------|---------------------------|
| Data should persist after PVC deletion | `Retain` |
| Storage should be deleted with PVC | `Delete` |
| Temporary, non-sensitive storage (legacy) | `Recycle` (Deprecated) |

---

## **Checking Reclaim Policy for Existing PVs**
To check the reclaim policy for all PVs in the cluster:
```sh
kubectl get pv
```
Example output:
```sh
NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM
pv-retain     5Gi        RWO            Retain          Bound    default/my-pvc
pv-delete     10Gi       RWO            Delete          Bound    default/fast-pvc
```

To update a PVâ€™s reclaim policy:
```sh
kubectl patch pv <pv-name> -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'
```

---

## **Conclusion**
- **`Retain`**: Keeps PV and data even after PVC deletion (requires manual cleanup).
- **`Delete`**: Automatically removes PV and storage (best for cloud environments).
- **`Recycle`**: Performs basic data cleanup and reuses the PV (**deprecated**).

ðŸš€ Would you like help setting up a specific reclaim policy for your use case?


### **Persistent Volume Claims (PVC):**
- A request for storage by a pod.
- **Dynamic Provisioning:** Automatically provisions a PV when a PVC is created.
  ![image](https://github.com/user-attachments/assets/28ccd67d-534c-4ca4-be9f-95fa30e78415)
  
  #### **When a Persistent Volume Claim (PVC) is created, Kubernetes follows a specific binding process to allocate storage.**
   - **1. PVC Requests Storage:** A PVC defines storage requirements such as:
        - Storage size (resources.requests.storage)
        - Access mode (ReadWriteOnce, ReadOnlyMany, ReadWriteMany)
        - Storage class (storageClassName)
    Kubernetes checks if an existing Persistent Volume (PV) can fulfill this request.
  - **2. Kubernetes Searches for a Matching PV:** Kubernetes looks for a PV that Has enough storage to meet or exceed the PVC request. Matches 
    the requested access mode (e.g., ReadWriteOnce). Uses the same StorageClass (if specified). Is not already bound to another PVC.
  - **3. Binding the PVC to a PV If a matching PV is found:**
       - The PV status changes to "Bound".
       - The PVC status changes to "Bound".
       - The storage is now reserved for this PVC and cannot be used by any other PVC.
     - If no matching PV exists:
       - The PVC remains in the "Pending" state until a suitable PV is available.
       - If dynamic provisioning is enabled, a new PV will be created automatically.
   - **4. Pod Uses the PVC:** A Pod references the PVC to mount the storage volume.The Pod does not directly interact with the PVâ€”it only knows the PVC.
### DEMO

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-retain
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: "/mnt/data-retain"  # This path is on your node
```

ðŸ”¹ This PV will **retain** data even if the claim is deleted.

---

### Persistent Volume Claim (`PVC`)

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-retain
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
```

ðŸ”¹ This **requests** 5Gi storage from `pv-retain`.

---

### Pod Using the PVC

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pvc-test
spec:
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: pvc-retain
  containers:
    - name: test-container
      image: busybox
      command: ["sleep", "3600"]
      volumeMounts:
        - mountPath: "/data"
          name: storage
```

ðŸ”¹ This Pod mounts the PVC at `/data`, so it sees the files stored in `/mnt/data-retain` on the host.
![image](https://github.com/user-attachments/assets/c4272baf-9557-4892-bef5-dec2087ba41a)

### **Storage Class:**
1. **Provisioner:** The backend storage responsible for provisioning.
2. **Parameters:** Define properties like storage size or type.
3. **Reclaim Policy:** Configured at the storage class level.

#### **Example Workflow:**
1. Define a **Storage Class** with specific parameters.
   - Example: Create a storage class for SSD-backed storage with high IOPS for database workloads.
2. Create a **PVC** to request storage from the defined class.
   - Example: Request a 10GB volume with `ReadWriteMany` access mode for shared access.
3. Automatically provision a **PV** based on the request.
4. Mount the PV to the pod for data persistence.
   - Example: Mount a dynamically provisioned PV to a MySQL pod for data storage.

---

## Quality of Service (QoS)



### **Goals:**
- Efficient resource management.
- Classify workloads based on resource requests and limits.

### **QoS Classes:**
1. **Guaranteed:**
   - Resources are fully reserved for the pod.
   - Example: A pod with exact resource requests and limits specified.
   - **Example:** Deploy a critical financial transaction processing pod with CPU and memory requests of 2 cores and 4GB respectively, ensuring consistent performance.

2. **Burstable:**
   - Some resource limits are set, but the pod can exceed requests.
   - Example: A pod with higher limits than requests.
   - **Example:** A `logging` pod with 500m CPU and 1GB memory requests but limits of 1 CPU and 2GB memory can burst when additional resources are available.

3. **BestEffort:**
   - No resource limits or requests specified.
   - Example: A pod that consumes resources only if available.
   - **Example:** Deploy an auxiliary data analysis pod without resource reservations, utilizing idle cluster resources.

---
