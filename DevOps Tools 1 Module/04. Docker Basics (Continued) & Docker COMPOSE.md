# **Docker Basics (Continued) & Docker Swarm**

This document covers advanced Docker topics, including **Storage Drivers**, **Logging Drivers**, **Namespaces**, **Control Groups**, **Docker Images**, and **Dockerfile** components. It provides detailed instructions and commands to help learners gain hands-on experience.

---

## **Agenda of the Lecture**
1. Selecting a Storage Driver  
2. Logging Drivers  
3. Namespace  
4. Control Groups (C Groups)  
5. Docker Images  
6. Dockerfile  

---

# **Selecting a Storage Driver**

### **What is a Storage Driver?**  
A **Storage Driver** is responsible for managing how data is **stored and accessed** within Docker containers. It handles how layers of images and containers interact with the filesystem.

---

### **Types of Storage Drivers**

1. **Overlay2 (Default Driver)**  
   - Most commonly used and default on Linux systems.  
   - Uses a **layered filesystem** where each Docker layer is stored as a snapshot.

2. **Device Mapper**  
   - Uses **thin provisioning** and **snapshots** to manage images and containers as virtual blocks.

3. **Btrfs**  
   - **Binary Tree Filesystem**.  
   - Supports **subvolumes** for flexible storage management.

4. **ZFS (Zettabyte File System)**  
   - Provides **copy-on-write**, **deduplication**, and **data protection** features.

---

### **Commands to Check and Change Storage Drivers**

1. **Check current storage driver**:  
   ```bash
   docker info | grep -i storage
   ```
2. **Change the storage driver** by modifying the **daemon.json** file:  
   ```bash
   vi /etc/docker/daemon.json
   ```
   Example configuration:  
   ```json
   {
       "storage-driver": "devicemapper"
   }
   ```

---

# **Logging Drivers**

### **What is a Logging Driver?**  
A **Logging Driver** manages how logs are generated, stored, and processed by Docker containers. By default, Docker captures logs through **stdout** and **stderr**.

---

### **Types of Logging Drivers**  
1. **json-file (Default)**  
2. **syslog**  
3. **awslogs**  
4. **fluentd**  
5. **journald**

---

---

## üê≥ Docker Logging Basics

### üîç Default Log Driver
- Check current driver:  
  ```bash
  docker info | grep "Logging Driver"
  ```

- Run container with specific driver:  
  ```bash
  docker run --log-driver=syslog ubuntu
  ```

- Set default driver globally in `/etc/docker/daemon.json`:
  ```json
  {
    "log-driver": "awslogs",
    "log-opts": {
      "awslogs-region": "us-west-2",
      "awslogs-group": "my-log-group",
      "awslogs-stream": "my-log-stream"
    }
  }
  ```

### üì¶ Common Logging Drivers
- `json-file` (default)  
- `syslog`  
- `journald` (stored in binary format)  
- `awslogs` (sends logs to Amazon CloudWatch)

### üõ† Example JSON Config for `json-file`
```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
```

### üìÑ Docker Log Commands
- View container logs:
  ```bash
  docker logs <container_id>
  ```

- Follow logs in real-time:
  ```bash
  docker logs -f <container_id>
  ```

- View last 10 lines:
  ```bash
  docker logs --tail 10 <container_id>
  ```

---

---

# **Namespace**

### **What is a Namespace?**  
A **Namespace** is a **Linux kernel feature** that Docker uses to isolate resources such as processes, users, and networks in containers.

---

### **Types of Namespaces**

| **Namespace Type** | **Description**                                                |
|--------------------|----------------------------------------------------------------|
| **PID**            | Isolates process IDs, ensuring container processes are isolated. |
| **User**           | Maps user and group IDs inside the container.                   |
| **MNT**            | Isolates filesystem mount points.                               |
| **IPC**            | Isolates inter-process communication resources.                 |
| **NET**            | Provides separate network interfaces for each container.        |

---

# **Control Groups (C Groups)**

### **What are C Groups?**  
**Control Groups (C Groups)** are used by Docker to **limit and manage resources** such as CPU, memory, and disk I/O for containers.

---

### **Example of Resource Limitation Using C Groups**

1. **Run an Nginx container with default resources**:  
   ```bash
   docker run -d --name first_container nginx
   ```

2. **Run a container with specific resource limits**:  
   ```bash
   docker run -d --name my_container --cpus="0.1" --memory="500m" nginx
   ```
   - **CPU Allocation**: 0.1 core  
   - **Memory Allocation**: 500 MB  

---

# **Docker Images**

### **What is a Docker Image?**  
A **Docker Image** is a **blueprint** used to create containers. It is a **read-only** template that contains instructions for building a container.

---

### **Ways to Create a Docker Image**

1. **Using a Dockerfile**  
2. **Using Commit Changes from a Container**  
   Example:  
   ```bash
   docker run -it ubuntu
   ```
   Make changes inside the container, then commit the changes:
   This will create a new image named my-custom-ubuntu from the current state of the container. 
   ```bash
   docker commit <container_id> new_image_name
   ```

4. **Using Docker Compose**  
   - Create a **docker-compose.yml** file to define multi-container applications.
5. **docker ps -aq: Lists all container IDs.
    docker rm $(...): Removes each container ID returned.**
  ```bash
  docker rm $(docker ps -aq)
  ```


---

# **Dockerfile**

### **What is a Dockerfile?**  
A **Dockerfile** is a text file containing instructions to build a Docker image.

---

### **Steps to Create a Dockerfile**  
1. **Create a Dockerfile**:  
   ```bash
   vi Dockerfile
   ```
2. **Write the following in the Dockerfile**:  
   ```dockerfile
   FROM ubuntu:latest
   WORKDIR /app
   COPY abc.txt /app/abc.txt
   CMD ["sleep", "infinity"]
   ```

3. **Build the Docker Image**:  
   ```bash
   docker build -t my_ubuntu_app .
   ```

4. **Run the Container**:  
   ```bash
   docker run -d --name my_container_2 my_ubuntu_app
   ```

5. **Check Running Containers**:  
   ```bash
   docker ps
   ```

6. **Access the Container**:  
   ```bash
   docker exec -it <container_id> /bin/bash
   ```

---

# **Components of a Dockerfile**

| **Instruction** | **Description**                                                  |
|-----------------|------------------------------------------------------------------|
| **FROM**        | Defines the base image.                                          |
| **RUN**         | Executes commands in a new layer.                                |
| **COPY**        | Copies files from the local machine to the Docker image.         |
| **ADD**         | Similar to COPY but supports remote URLs and file extraction.    |
| **WORKDIR**     | Sets the working directory inside the container.                 |
| **CMD**         | Defines the default executable for the Docker image.             |
| **ENTRYPOINT**  | Configures the container to run as an executable.                |
| **ENV**         | Sets environment variables in the image.                         |
| **VOLUME**      | Creates a mount point for persistent data storage.               |

---

### ‚úÖ Correct Usage

#### Using `COPY`:
```Dockerfile
COPY hello.py /app/
```

#### Using `ADD`:
```Dockerfile
ADD hello.py /app/
```

Both commands copy the `hello.py` file from your local directory (where the Dockerfile is) into the `/app` directory **inside** the Docker image.

---

### üìå COPY vs ADD ‚Äì What‚Äôs the difference?

| Feature | `COPY` | `ADD` |
|--------|--------|------|
| Copy local files | ‚úÖ | ‚úÖ |
| Extract TAR files automatically | ‚ùå | ‚úÖ |
| Download from URL | ‚ùå | ‚úÖ |
| Simpler, recommended for basic copying | ‚úÖ | ‚ùå |

> ‚úÖ Use `COPY` for most use cases. Use `ADD` only if you need its extra features.

---


### **Difference Between CMD and ENTRYPOINT**  

Both `CMD` and `ENTRYPOINT` are instructions used in a Dockerfile to define what command runs in a container **by default**, but they serve slightly different purposes. Here's a breakdown:

---

### üîπ `CMD` (Command)
- **Purpose:** Provides **default arguments** for the container's execution.
- **Can be overridden** at runtime using `docker run <image> <new command>`.

#### Example:
```Dockerfile
FROM ubuntu
CMD ["echo", "Hello from CMD"]
```
Running:
```bash
docker run myimage
# Output: Hello from CMD

docker run myimage echo "Overridden"
# Output: Overridden
```

---

### üîπ `ENTRYPOINT`
- **Purpose:** Sets the **main command** that will always run when the container starts.
- **Cannot be easily overridden** unless you use `--entrypoint`.

#### Example:
```Dockerfile
FROM ubuntu
ENTRYPOINT ["echo", "Hello from ENTRYPOINT"]
```
Running:
```bash
docker run myimage
# Output: Hello from ENTRYPOINT

docker run myimage World
# Output: Hello from ENTRYPOINT World
```

To override:
```bash
docker run --entrypoint echo myimage "Overridden"
# Output: Overridden
```

---

### üî∏ Using Both Together
You can combine `ENTRYPOINT` and `CMD`:
```Dockerfile
FROM ubuntu
ENTRYPOINT ["echo"]
CMD ["Default CMD text"]
```
Running:
```bash
docker run myimage
# Output: Default CMD text

docker run myimage "Overridden CMD text"
# Output: Overridden CMD text
```

In this setup:
- `ENTRYPOINT` is the fixed command.
- `CMD` provides default arguments for the `ENTRYPOINT`.

---
important part of Dockerfile behavior ‚Äî **`CMD` vs `ENTRYPOINT`**, how they work, and how they interact. Let‚Äôs clean up and explain everything in order, using your examples.

---

### üêç **hello.py**

```python
import sys
print("Hello,", " ".join(sys.argv[1:]))
```

---

### üìÑ **Dockerfile Example: CMD vs ENTRYPOINT**

```Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY hello.py .

ENTRYPOINT ["python", "hello.py"]
CMD ["World!"]
```

---

### üß† Explanation:

- **ENTRYPOINT** defines the **main executable** of the container.
- **CMD** provides **default arguments** to that executable.
- If you run:

  ```bash
  docker run cmd-vs-entrypoint-demo Alice
  ```

  ‚Üí This runs:  
  ```bash
  python hello.py Alice
  ```

  ‚úÖ Output: `Hello, Alice`

- If you run:

  ```bash
  docker run cmd-vs-entrypoint-demo
  ```

  ‚Üí This runs:  
  ```bash
  python hello.py World!
  ```

  ‚úÖ Output: `Hello, World!`

- If you override the **ENTRYPOINT**:

  ```bash
  docker run --entrypoint echo cmd-vs-entrypoint-demo "Hello from new entrypoint!"
  ```

  ‚úÖ Output: `Hello from new entrypoint!`

---

### ‚ùóMultiple CMDs and ENTRYPOINTs

```Dockerfile
FROM ubuntu:latest

CMD echo "This is the first CMD"
CMD echo "This is the second CMD"
CMD echo "This is the last CMD"

ENTRYPOINT ["echo", "This is ENTRYPOINT 1"]
ENTRYPOINT ["echo", "This is ENTRYPOINT 2"]
```

### üßæ Output:
- Only the **last CMD** and **last ENTRYPOINT** are used.
- So this will run as if:
  ```bash
  echo This is ENTRYPOINT 2
  ```

‚úÖ Result:
```
This is ENTRYPOINT 2
```
---
### ‚úÖ Summary Table

![image](https://github.com/user-attachments/assets/cbd6fcd0-9834-4327-ac55-8c559c0a3abb)


---

---

### **Example Dockerfile with Components**
```dockerfile
FROM ubuntu:latest
RUN apt-get update && apt-get install -y python3
WORKDIR /app
COPY . /app
CMD ["python3", "-m", "http.server", "8080"]
```

---
How to use Dockerfile instructions like `ENV`, `EXPOSE`, `VOLUME`, and `LABEL`. Let me clarify each of these with correct syntax and explain what they do ‚Äî along with how **data is shared** between **host and container** using `VOLUME`.

---

### ‚úÖ Correct Usage and Meaning

#### üîπ `ENV` ‚Äî Set Environment Variables
```Dockerfile
ENV APP_ENV=Production
```
- Sets an environment variable `APP_ENV` with the value `Production`.
- Accessible in the container with `$APP_ENV`.

---

#### üîπ `EXPOSE` ‚Äî Declare Container Port
```Dockerfile
EXPOSE 80
```
- Tells Docker that the container will listen on **port 80**.
- It's **documentation only** unless you map ports using `-p` when running.

---

#### üîπ `VOLUME` ‚Äî Create Mount Point
```Dockerfile
VOLUME ["/data"]
```
- Creates a mount point at `/data` in the container.
- Docker will manage this volume unless you map it to a host path.

---

#### üîπ `LABEL` ‚Äî Add Metadata
```Dockerfile
LABEL version="1.0"
```
- Adds metadata to the image (e.g., version, description, maintainer).

---

### üîÑ Data Sharing: Host ‚Üî Container (`VOLUME` and Bind Mounts)

To share data between **host** and **container**, you can use a **bind mount** or **named volume** at runtime:

#### üîπ Bind Mount Example (host to container):
```bash
docker run -v /host/data:/data myimage
```
- `/host/data` is a directory on your machine.
- `/data` is the path inside the container.
- Changes in either are visible in both.

#### üîπ Named Volume Example:
```bash
docker volume create mydata
docker run -v mydata:/data myimage
```
- Docker manages `mydata` and keeps it persistent even if container is removed.

---

### üöÄ Sample Dockerfile Using All:
```Dockerfile
FROM ubuntu

ENV APP_ENV=Production
EXPOSE 80
VOLUME ["/data"]
LABEL version="1.0"

CMD ["bash"]
```
# **Key Docker Commands Recap**

| **Command**                | **Description**                                                |
|----------------------------|----------------------------------------------------------------|
| `docker ps`                 | Lists all running containers.                                  |
| `docker pull <image>`       | Pulls an image from the Docker registry.                       |
| `docker run <image>`        | Runs a container based on the given image.                     |
| `docker stop <container_id>`| Stops a running container.                                     |
| `docker exec -it <id>`      | Accesses a running container.                                  |
| `docker build -t <name> .`  | Builds a Docker image using a Dockerfile.                      |
| `docker commit <id> <name>` | Creates an image from a container's changes.                   |

Absolutely! Here's a combined explanation that answers both:

---


# üê≥ What is Docker Compose?

**Docker Compose** is a tool that allows you to define and manage multi-container Docker applications using a YAML file called `docker-compose.yml`.

It simplifies starting, stopping, and managing multiple containers with just a few simple commands.

---

### ‚úÖ Why Use Docker Compose?

- Manage multiple containers (like web + database) together
- Reproducible setup for development, testing, and CI/CD
- Easy to configure services, networks, volumes, and environment variables

---

## üîß Example: Nginx + MySQL with Docker Compose

Here‚Äôs a working `docker-compose.yml` file that sets up:

- `Nginx` running on port **8080**
- `MySQL 5.7` with root password `example`, running on port **3306**

```yaml
version: '3'

services:
  web:
    image: nginx
    container_name: webserver
    ports:
      - "8080:80"

  db:
    image: mysql:5.7
    container_name: mysql_db
    environment:
      MYSQL_ROOT_PASSWORD: example
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql

volumes:
  mysql_data:
```

### üîí These names are **predefined** environment variable names expected by the **MySQL Docker image** (official image from Docker Hub).

So you **must use them exactly as shown**:

| Environment Variable     | Purpose                                                       |
|--------------------------|---------------------------------------------------------------|
| `MYSQL_DATABASE`         | Creates a database with this name when the container starts.  |
| `MYSQL_USER`             | Creates a new user (in addition to root).                     |
| `MYSQL_PASSWORD`         | Sets the password for the above user.                         |
| `MYSQL_ROOT_PASSWORD`    | **Required.** Sets the password for the MySQL root user.      |

---

### ‚ùå You **cannot rename** them to something like:
```yaml
MY_DB_NAME: wordpress
MY_DB_USER: wpuser
```
Because the **MySQL image won't recognize** those ‚Äî and it won't initialize properly.

---

### ‚úÖ However, you *can* use **custom names** inside your app (like in WordPress `environment`) ‚Äî just make sure the values match what you gave MySQL:

```yaml
# WordPress container
environment:
  WORDPRESS_DB_HOST: db
  WORDPRESS_DB_USER: wordpress     # must match MYSQL_USER in db
  WORDPRESS_DB_PASSWORD: wordpress # must match MYSQL_PASSWORD in db
  WORDPRESS_DB_NAME: wordpress     # must match MYSQL_DATABASE in db
```

So WordPress knows how to connect to MySQL properly.

---
---

### ‚ñ∂Ô∏è Docker Compose Commands

| Command | Description |
|---------|-------------|
| `docker compose up` | Starts all services (web + db) |
| `docker compose up -d` | Starts in detached mode (background) |
| `docker compose down` | Stops and removes all services, volumes, networks |
| `docker compose logs` | Shows logs from all services |
| `docker compose logs db` | Shows logs only from the MySQL service |
| `docker compose ps` | Lists running services and their status |

---

### üìù Notes

- `8080:80` ‚Üí Access Nginx in your browser at `http://localhost:8080`
- `3306:3306` ‚Üí MySQL accessible on the default port
- `volumes` ensure MySQL data persists even if the container is removed

---

---

# üß† What does `--cpus="0.5"` do?

This flag **limits the container's CPU usage** to **half a CPU core**, or **50% of a single core‚Äôs processing time**.

---

### üñ•Ô∏è How does Docker enforce this?

Docker uses the **Linux cgroups (control groups)** feature to restrict CPU usage. When you pass `--cpus="0.5"`, you're telling Docker to allow the container to use **no more than 50% of one CPU‚Äôs processing time over a period of time**.

This doesn‚Äôt mean the container gets **half a physical CPU core** locked for it ‚Äî instead, it gets **half the time slice** for CPU scheduling.

---

### üìä Example Scenario:

You run:

```bash
docker run -it --cpus="0.5" ubuntu
```

- Suppose your system has 4 CPU cores.
- This container will be allowed to use **up to 50% of one core**.
- If the container tries to use more CPU (e.g., via an infinite loop), the CPU scheduler will throttle it to ensure it doesn‚Äôt exceed the 0.5 CPU quota.

---

### üîß Behind the Scenes (for Linux nerds):

Under the hood, Docker sets:
```bash
cpu-quota = 50000
cpu-period = 100000
```

- `cpu-period` = 100,000 microseconds (100ms)
- `cpu-quota` = 50,000 microseconds (50ms)
- So the container can only run for 50ms every 100ms ‚Üí **50% usage**

---
 Let‚Äôs break down both `--memory` and `--cpuset-cpus` so you fully understand how to control memory and CPU *pinning* in Docker.

---

## üß† `--memory`

### ‚ùìWhat it does:
Limits the **maximum RAM** the container can use.

### ‚úÖ Example:
```bash
docker run -it --memory="256m" ubuntu
```

- This limits the container to **256 megabytes** of RAM.
- If the container exceeds this, it will **be killed** by the kernel's OOM (Out-Of-Memory) killer.

### üîß Supported formats:
- `b`, `k`, `m`, `g` for bytes, kilobytes, megabytes, gigabytes

> E.g. `--memory="1g"` or `--memory="1024m"`

---

### üß™ Optional: Soft Limit

You can also set a *soft limit*:

```bash
--memory-reservation="128m"
```

- This is the memory the container *should ideally* stay under.
- If system memory runs low, containers above this limit are throttled first.

---

## üß† `--cpuset-cpus`

### ‚ùìWhat it does:
Pins the container to run **only on specific CPU cores**.

### ‚úÖ Example:
```bash
docker run -it --cpuset-cpus="0,2" ubuntu
```

- This restricts the container to only run on **CPU cores 0 and 2**.
- It's useful for performance tuning, real-time apps, or isolating workloads.

---

### üß™ Example Usage with Both:

```bash
docker run -it \
  --memory="512m" \
  --cpus="1.5" \
  --cpuset-cpus="1,2" \
  ubuntu
```

This container:
- Can use max 512MB RAM
- Gets 1.5 CPUs' worth of scheduling time
- But can only run on CPU cores 1 and 2

---

## üìä Monitor Resource Usage

Use:
```bash
docker stats
```

To see:
- CPU %
- Memory usage / limit
- Network I/O
- Block I/O

---


