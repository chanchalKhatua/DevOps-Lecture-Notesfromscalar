# **Docker Container Networking and Security**

This document provides a detailed discussion on **Docker Storage**, **Storage Drivers**, **NFS (Network File System)**, and **Docker Networking**. It explains how data is stored and managed in Docker containers and how Docker networking enables interaction between isolated containers.

---

## **Topics to be discussed:**

1. Docker Storage  
2. Storage Drivers  
3. NFS (Network File System)  
4. Docker Networking  

---

# 🐳 Introduction to Docker Storage

Docker Storage refers to the methods used to **persist data** in Docker containers and manage **container file systems**.

---

### **Why Do We Need Storage in Docker?**  
1. **Data Persistence**: Ensures that data remains available even if the container is deleted.  
2. **Scalability and Flexibility**: Allows storage to be adjusted as needed for various applications.  
3. **Efficient Resource Management**: Prevents duplication of data across containers.  
4. **High Availability and Reliability**: Ensures data remains accessible during container failures.

---
## 📦 Docker Image Layers: Read-Only  
A Docker image is made of several **read-only layers** (OS, libraries, app code). When you run a container from that image, Docker adds a **writable layer on top** of the image stack.

---

### ✍️ Writable Layer (Copy-on-Write):

- When a container writes to a file that exists in a lower (read-only) image layer:
  - Docker **copies that file** from the image layer into the **writable container layer**
  - The container **modifies the copy**, not the original
- This is called **Copy-on-Write (CoW)**
---
![image](https://github.com/user-attachments/assets/de74394f-1d5c-4fe1-a848-96f9fc472850)

---

### 🧠 Key Points:

- **Writable Layer is ephemeral**: Data is lost if the container is removed.
- **Efficient**: Only modified data is copied, saving storage space.
- **Used for**: Logs, temp files, and any non-persistent data.

---
## ⚡ Ephemeral Storage (Temporary)

- **Exists only during container lifetime**
- Data is **lost** when the container stops or is removed
- Stored in the container's writable layer (Copy-on-Write)

### 🔸 Characteristics:
- Image layers = **Read-only**
- Container layer = **Writable**
- Best for **short-term tasks** or **stateless apps**

---

## 💾 Persistent Storage

- Survives container stop/restart/removal
- Used to **retain data** beyond container lifecycle
- Critical for **databases, user uploads, logs**, etc.

---

## 🛠️ Docker Storage Types

### 1. **Volumes** (Preferred)

- Managed by Docker
- Stored in: `/var/lib/docker/volumes/`
- Portable, safe, and works well with Docker Swarm

#### 🔹 Create a volume:
```bash
docker volume create my-volume
```

#### 🔹 Use volume in a container:
```bash
docker run -d -v my-volume:/data nginx
```

---

### 2. **Bind Mounts**

- Mounts a **specific path** from host into container
- Direct access to host files

#### 🔹 Example:
```bash
docker run -d -v /host/data:/container/data my_image
```

#### ⚠️ Less Portable:
- Tightly coupled with host file system
- Not ideal for sharing across environments

---

### 3. **tmpfs Mounts** (In-Memory)

- Temporary storage in **RAM**
- Super fast, no disk I/O
- **Data lost on restart** or shutdown

#### 🔹 Example:
```bash
docker run -it --rm --tmpfs /app/cache:size=64m ubuntu bash
```
---
![image](https://github.com/user-attachments/assets/61f8852a-e6fc-4e52-9631-127a9269a1ed)
---
## 📌 Quick Comparison

| Type         | Persistent | Fast | Portable | Use Case                     |
|--------------|------------|------|----------|------------------------------|
| Volume       | ✅         | ⚪    | ✅       | Databases, logs              |
| Bind Mount   | ✅         | ⚪    | ❌       | Host-config access, dev work |
| tmpfs        | ❌         | ✅   | ❌       | Caching, sensitive data      |

---



---
## **creating and managing Docker volumes**, where one container writes to the volume and another reads from it — demonstrating shared data:

---

### 🔧 **1. Create a Docker Volume**
```bash
docker volume create shared-volume
```

---

### 🔍 **2. Inspect the Volume (Optional)**
```bash
docker volume inspect shared-volume
```

---

### 📃 **3. List Available Volumes**
```bash
docker volume ls
```

---

### 📝 **4. Launch the First Container (Writer)**
Mount the volume and get a shell:
```bash
docker run -it --name writer-container -v shared-volume:/app/data ubuntu bash
```

Now, inside the container, write data:
```bash
echo "This data is present on shared-volume!" > /app/data/message.txt
exit
```

---

### 📖 **5. Launch the Second Container (Reader)**
Also mount the same volume:
```bash
docker run -it --name reader-container -v shared-volume:/app/data ubuntu bash
```

Inside this container, read the data:
```bash
cat /app/data/message.txt
# Output: This data is present on shared-volume!
exit
```

---

### 🧹 **(Optional) Cleanup**
Stop and remove containers and volume:
```bash
docker rm -f writer-container reader-container
docker volume rm shared-volume
```
This is a great basic example of **persistent data sharing** using Docker volumes.

---
---

## 🧪 **Demo: Backing Up a Docker Volume Using a Temporary Container**

#### 1. **Create a backup directory on the host**
```bash
mkdir -p ~/docker-backup
```

#### 2. **(Optional) Create and use a volume**
Let’s assume you already have a named volume `shared-volume`. If not:
```bash
docker volume create shared-volume
```

#### 3. **(Optional) Add data to the volume**
You can use a temporary container to put a file into the volume:
```bash
docker run --rm -v shared-volume:/data alpine sh -c "echo 'This is a message' > /data/message.txt"
```

#### 4. **Back up the volume using a temporary container**
```bash
docker run --rm \
  -v shared-volume:/data \
  -v ~/docker-backup:/backup \
  ubuntu \
  tar -czf /backup/shared-volume-backup.tar.gz -C /data .
```

#### ✅ Result:
- A compressed backup of your `shared-volume` is saved as:
```bash
~/docker-backup/shared-volume-backup.tar.gz
```
---

## ♻️ **Demo: Restoring a Docker Volume Backup**

#### ✅ Prerequisites:
- Backup file: `~/docker-backup/shared-volume-backup.tar.gz`
- Target volume: `shared-volume` (or any name you prefer)

---

#### 1. **Ensure the volume exists (create if needed)**

```bash
docker volume create shared-volume
```

#### 2. **Restore the backup to the volume**

```bash
docker run --rm \
  -v shared-volume:/data \
  -v ~/docker-backup:/backup \
  ubuntu \
  bash -c "cd /data && tar -xzf /backup/shared-volume-backup.tar.gz"
```

---

#### 📂 To Verify:
You can check the contents using another temporary container:

```bash
docker run --rm -v shared-volume:/data alpine ls /data
```

You should see `message.txt` or whatever data was in the backup.

---

---


## ❓ Why do we take backup of Docker volumes using a temporary container instead of copying `/var/lib/docker/volumes/` directly?

The primary reason is to ensure **data consistency**, **portability**, and **security**, while avoiding interference with Docker’s internal mechanisms.

---

### ✅ 1. Data Consistency

- **Active Containers:**  
  If a container is actively using the volume, files inside `/var/lib/docker/volumes/` may be **modified during the backup**, leading to **corrupted or incomplete data**.

- **Temporary Container Approach:**  
  By attaching the volume to a **dedicated temporary container**, you can:
  - Isolate the volume
  - Pause or manage write operations
  - Ensure the data is **in a stable state** before backing it up

---

### ✅ 2. Portability

- The path `/var/lib/docker/volumes/` is **not guaranteed** to be the same across all systems.
- Docker might store volumes elsewhere depending on the **OS, Docker version**, or **custom configurations**.
- Using the Docker CLI or containers ensures a more **portable and reliable** approach.

---

### ✅ 3. Permissions and Security

- Accessing `/var/lib/docker/volumes/` directly typically requires **root privileges**.
- This can lead to:
  - **Permission issues**
  - **Security risks**
  - Accidental modification of sensitive Docker files

---

### ✅ 4. Avoiding Internal Docker Structure

- The `/var/lib/docker/volumes/` directory contains not only user data but also **Docker’s internal metadata**.
- Accidentally copying or tampering with this structure can **break volume functionality**.

---

### 🔑 Summary

> Backing up Docker volumes using a temporary container provides a **safe, consistent, and platform-agnostic** method, avoiding the risks associated with directly accessing Docker’s internal directories.

---


---

## **Question:**

You are building a Dockerized web application that uses a **PostgreSQL database** to store user data. The application has the following requirements:

1. **Data Persistence:** The database data must not be lost when the container is restarted or removed.  
2. **Portability:** You need the ability to back up and restore the database easily.  
3. **Host Accessibility:** Developers occasionally need direct access to the database files for debugging or manual modifications.  

**Which Docker storage type would you use in this scenario, and why?**

- **A)** Ephemeral Storage (container writable layer)  
- **B)** Volume  
- **C)** Bind Mount  
- **D)** tmpfs Mount  

---

### **Answer:**  
**B) Volume**

---

### **Why:**  

**✅ Volume is the best choice because:**

1. **Data Persistence:**  
   - Volumes persist data even when the container is stopped or removed, meeting requirement **#1**.

2. **Portability:**  
   - Volumes can easily be backed up and restored with Docker commands:
     ```bash
     # Backup
     docker run --rm -v my_pgdata:/volume -v $(pwd):/backup alpine tar czf /backup/pgdata.tar.gz -C /volume .
     
     # Restore
     docker run --rm -v my_pgdata:/volume -v $(pwd):/backup alpine tar xzf /backup/pgdata.tar.gz -C /volume
     ```
   - This satisfies **#2**.

3. **Host Accessibility:**  
   - Volume data is stored in:
     ```
     /var/lib/docker/volumes/<volume_name>/_data/
     ```
   - Developers can access this path for manual debugging, satisfying **#3**.

---

### ❌ Why not the others:

- **A) Ephemeral Storage:**  
  - Data is lost when the container is removed. Does **not** support persistence (**#1** fails).

- **C) Bind Mount:**  
  - Gives direct host access (**#3** OK), but:
    - Less portable across OS and environments (**#2** suffers).
    - Risk of host-side file corruption or inconsistent behavior.
    - Not ideal for production-grade setups.

- **D) tmpfs Mount:**  
  - Data is stored in memory and lost on restart. Not persistent (**#1** fails).

---

### ✅ Conclusion:
> **Use Docker Volume** to achieve persistent storage, easy backup/restore, and controlled host access for PostgreSQL containers.

---
---

# **Storage Drivers**

Docker uses **Storage Drivers** to manage how data is **stored and accessed** in the container’s filesystem.

---

### **Types of Storage Drivers**

1. **Overlay2 (Default Driver)**  
   - Uses **Copy-on-Write** mechanism.  
   - A **base image** is shared across multiple containers, with each container having its own **read-write layer**.

   **Example:**  
   - Containers **C1**, **C2**, and **C3** use the same base image layer, but each has a unique **read-write layer** for modifications.

---

2. **AUFS (Advanced Multilayer Universal File System)**  
   - Supports **Copy-on-Write**.  
   - Combines multiple layers of files into a **unified view**.

---

3. **Device Mapper**  
   - Uses **block-level operations** to allocate storage.  
   - Ideal for systems that need **block-level management** and **high performance**.

---

### **Important Command: Cleaning Unused Volumes**  
```bash
docker volume prune
```
- Deletes **unused volumes** to free up space.

---

# **NFS (Network File System)**

### **What is NFS?**  
NFS is a **shared storage solution** that allows multiple machines to **access the same storage** over a network.

---

### **When to Use NFS?**  
- When you have **multiple machines** and want them to use **shared storage**.  
- **Example:**  
  - You have **3 servers** that need to access the **same database files**.

---

### **Setup Steps for NFS**  
1. **Install NFS Kernel on the Server**  
   ```bash
   apt-get install nfs-kernel-server
   ```
2. **Install NFS on Client Machines**  
   ```bash
   apt-get install nfs-common
   ```

---

# **Docker Networking**

Docker Networking allows **containers** to communicate with:  
- Each other.  
- The **host machine**.  
- **External networks**.

---

### **Why is Docker Networking Important?**  
- Docker containers are **isolated** by default.  
- Networking provides a **logical layer** for containers to **interact** securely.

---

### **Types of Docker Networks**

1. **Bridge Network**  
   - The **default network** for Docker containers.  
   - Containers can communicate **within the same host**.  
   - Ideal for **local development**.

2. **Host Network**  
   - Removes the **network isolation** between the container and the host.  
   - The container shares the **host’s network stack**.

3. **None Network**  
   - Completely disables networking for the container.  
   - Ideal for **security-focused** applications.

4. **Overlay Network**  
   - Used in **Docker Swarm** to enable communication between containers across **multiple hosts**.

5. **Macvlan Network**  
   - Assigns a **unique MAC address** to each container.  
   - Containers appear as **separate devices** on the network.

---

# **Summary of Key Commands**

| **Command**                            | **Description**                                     |
|----------------------------------------|-----------------------------------------------------|
| `docker volume create <name>`           | Creates a Docker volume.                           |
| `docker run -d -v <volume>:/path`       | Mounts a volume inside the container.               |
| `docker volume prune`                   | Removes unused volumes.                            |
| `docker network create <name>`          | Creates a new Docker network.                      |
| `docker network ls`                     | Lists all Docker networks.                         |
| `docker network connect <net> <cont>`   | Connects a container to a network.                 |
| `docker run --network=<network>`        | Runs a container in a specific network.             |

---

# **Example Docker Networking Commands**

1. **Creating a Bridge Network**  
   ```bash
   docker network create my_bridge
   ```

2. **Running a Container in a Custom Network**  
   ```bash
   docker run -d --name my_container --network=my_bridge nginx
   ```

3. **Inspecting a Network**  
   ```bash
   docker network inspect my_bridge
   ```

4. **Connecting an Existing Container to a Network**  
   ```bash
   docker network connect my_bridge my_container
   ```

---

# **Conclusion**

In this session, we explored:  
- **Docker Storage** methods for persisting data in containers.  
- **Storage Drivers** used to manage container filesystems.  
- **NFS (Network File System)** for shared storage across machines.  
- **Docker Networking** to enable communication between containers and external systems.
